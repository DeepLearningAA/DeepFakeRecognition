{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Fake Detection. ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from dataset_handlers.resnet.resnet_feature_dataset import FeatureDataset\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo resnet18 es un modelo de red neuronal convolucional que fue entrenado para clasificar imágenes en 1000 clases. En este caso, se utilizará el modelo pre-entrenado para clasificar imágenes en 2 clases: real y fake. Se trata de una arquitectura de red residual, que permite entrenar redes más profundas sin que se produzca el problema del desvanecimiento del gradiente. Para más información, consultar el artículo [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nn.Sequential(\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Tanh(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.Linear(64, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FeatureDataset(\n",
    "    root_path='data/real_and_fake_restnet',\n",
    "    transform=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Dropout(p=0.5, inplace=False)\n",
       "  (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "l1_factor = 0.0001\n",
    "l2_factor = 0.001\n",
    "\n",
    "k_folds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=0.0001, weight_decay=l2_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data_loader, model):\n",
    "    acc = 0\n",
    "    for i, (image, label) in enumerate(data_loader, 1):\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = classifier(image)\n",
    "        acc += (torch.argmax(output, dim=1) == label).sum().item()\n",
    "\n",
    "    return acc / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, critereon, optimizer, train_loader, test_loader, num_epochs, l1_factor):\n",
    "    acc_training_set = []\n",
    "    acc_val_set = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (image, label) in enumerate(train_loader, 1):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = critereon(output, label)\n",
    "\n",
    "            l1_regularization = torch.tensor(0., requires_grad=False)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "\n",
    "            l1_regularization.requires_grad_(True)\n",
    "            loss += l1_factor * l1_regularization\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                acc_training_set.append(accuracy(train_loader, model))\n",
    "                acc_val_set.append(accuracy(test_loader, model))\n",
    "\n",
    "                print('Epoch: {:2.0f}/{}, Batch: {:2.0f}, Loss: {:.6f}, Acc (train): {:.6f}, Acc (val): {:.6f}'\n",
    "                    .format(epoch+1, num_epochs, i, loss.item(), acc_training_set[-1], acc_val_set[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/20, Batch: 10, Loss: 0.878209, Acc (train): 0.492034, Acc (val): 0.486553\n",
      "Epoch:  1/20, Batch: 20, Loss: 0.988793, Acc (train): 0.505515, Acc (val): 0.491443\n",
      "Epoch:  2/20, Batch: 10, Loss: 0.996351, Acc (train): 0.478554, Acc (val): 0.491443\n",
      "Epoch:  2/20, Batch: 20, Loss: 1.014334, Acc (train): 0.496936, Acc (val): 0.488998\n",
      "Epoch:  3/20, Batch: 10, Loss: 0.928588, Acc (train): 0.506127, Acc (val): 0.491443\n",
      "Epoch:  3/20, Batch: 20, Loss: 1.018288, Acc (train): 0.477941, Acc (val): 0.479218\n",
      "Epoch:  4/20, Batch: 10, Loss: 0.975922, Acc (train): 0.516544, Acc (val): 0.530562\n",
      "Epoch:  4/20, Batch: 20, Loss: 0.893362, Acc (train): 0.494485, Acc (val): 0.476773\n",
      "Epoch:  5/20, Batch: 10, Loss: 0.919093, Acc (train): 0.479167, Acc (val): 0.501222\n",
      "Epoch:  5/20, Batch: 20, Loss: 0.957953, Acc (train): 0.517157, Acc (val): 0.498778\n",
      "Epoch:  6/20, Batch: 10, Loss: 0.952879, Acc (train): 0.506127, Acc (val): 0.501222\n",
      "Epoch:  6/20, Batch: 20, Loss: 0.954302, Acc (train): 0.501225, Acc (val): 0.513447\n",
      "Epoch:  7/20, Batch: 10, Loss: 0.967268, Acc (train): 0.493873, Acc (val): 0.513447\n",
      "Epoch:  7/20, Batch: 20, Loss: 0.960802, Acc (train): 0.518382, Acc (val): 0.511002\n",
      "Epoch:  8/20, Batch: 10, Loss: 0.918704, Acc (train): 0.498775, Acc (val): 0.479218\n",
      "Epoch:  8/20, Batch: 20, Loss: 0.926340, Acc (train): 0.510417, Acc (val): 0.520782\n",
      "Epoch:  9/20, Batch: 10, Loss: 0.873211, Acc (train): 0.501838, Acc (val): 0.501222\n",
      "Epoch:  9/20, Batch: 20, Loss: 0.902718, Acc (train): 0.523284, Acc (val): 0.498778\n",
      "Epoch: 10/20, Batch: 10, Loss: 0.929963, Acc (train): 0.493873, Acc (val): 0.484108\n",
      "Epoch: 10/20, Batch: 20, Loss: 0.884122, Acc (train): 0.503064, Acc (val): 0.508557\n",
      "Epoch: 11/20, Batch: 10, Loss: 0.853063, Acc (train): 0.485294, Acc (val): 0.550122\n",
      "Epoch: 11/20, Batch: 20, Loss: 0.815226, Acc (train): 0.503676, Acc (val): 0.488998\n",
      "Epoch: 12/20, Batch: 10, Loss: 0.925950, Acc (train): 0.509191, Acc (val): 0.545232\n",
      "Epoch: 12/20, Batch: 20, Loss: 0.861710, Acc (train): 0.523897, Acc (val): 0.520782\n",
      "Epoch: 13/20, Batch: 10, Loss: 0.938459, Acc (train): 0.503676, Acc (val): 0.555012\n",
      "Epoch: 13/20, Batch: 20, Loss: 0.864979, Acc (train): 0.514093, Acc (val): 0.513447\n",
      "Epoch: 14/20, Batch: 10, Loss: 0.911651, Acc (train): 0.507353, Acc (val): 0.537897\n",
      "Epoch: 14/20, Batch: 20, Loss: 0.953097, Acc (train): 0.492034, Acc (val): 0.481663\n",
      "Epoch: 15/20, Batch: 10, Loss: 0.890593, Acc (train): 0.481005, Acc (val): 0.515892\n",
      "Epoch: 15/20, Batch: 20, Loss: 0.920304, Acc (train): 0.502451, Acc (val): 0.464548\n",
      "Epoch: 16/20, Batch: 10, Loss: 0.844771, Acc (train): 0.505515, Acc (val): 0.469438\n",
      "Epoch: 16/20, Batch: 20, Loss: 0.883078, Acc (train): 0.517157, Acc (val): 0.520782\n",
      "Epoch: 17/20, Batch: 10, Loss: 0.917376, Acc (train): 0.490196, Acc (val): 0.508557\n",
      "Epoch: 17/20, Batch: 20, Loss: 0.888682, Acc (train): 0.492647, Acc (val): 0.498778\n",
      "Epoch: 18/20, Batch: 10, Loss: 0.891032, Acc (train): 0.511029, Acc (val): 0.508557\n",
      "Epoch: 18/20, Batch: 20, Loss: 0.914494, Acc (train): 0.513480, Acc (val): 0.457213\n",
      "Epoch: 19/20, Batch: 10, Loss: 0.932724, Acc (train): 0.513480, Acc (val): 0.528117\n",
      "Epoch: 19/20, Batch: 20, Loss: 0.825823, Acc (train): 0.512255, Acc (val): 0.545232\n",
      "Epoch: 20/20, Batch: 10, Loss: 0.904202, Acc (train): 0.509804, Acc (val): 0.515892\n",
      "Epoch: 20/20, Batch: 20, Loss: 0.884788, Acc (train): 0.505515, Acc (val): 0.503667\n"
     ]
    }
   ],
   "source": [
    "train_model(classifier, criterion, optimizer, train_loader, test_loader, num_epochs, l1_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
